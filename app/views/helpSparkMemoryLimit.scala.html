<p>The total memory limit of a Spark job is XXX. You really, really want to be clear of that limit or your job may
  occupy too many resources that slow down the entire cluster. Also we keep track of the peak
  memory used for storage, normally the memory utilization rate should be higher than [a number]. Otherwise, it means
  you don't the memory you claimed to need.
</p>
<h3>Suggestions</h3>
<p>
  Make memory utilization rate higher than 0.5.
</p>
