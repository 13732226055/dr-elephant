<p>
    This heuristic gauges your mapper performance in a disk I/0 perspective. Mapper spill ratio (spilled records/output records) is a critical indicator to your mapper performance: if the ratio is close to 2, it generally means your mappers have large outputs that couldn't fit in in-memory sort buffer. If the ratio is higher than 2, the situation is even worse. Having large disk I/O wasted on sorting output records could seriously affect your mapper speed. To make it run faster, try our tentative recommendation. We newly enabled this heuristic and is still testing it! <br>
</p>
<p>

</p>
<h5>Example</h5>
<p>
<div class="list-group">
    <a class="list-group-item list-group-item-danger" href="">
        <h4 class="list-group-item-heading">Mapper Spill</h4>
        <table class="list-group-item-text table table-condensed left-table">
            <thead><tr><th colspan="2">Severity: Critical</th></tr></thead>
            <tbody>
            <tr>
                <td>Number of spilled records</td>
                <td>15000</td>
            </tr>
            <tr>
                <td>Number of Mapper output records</td>
                <td>7500</td>
            </tr>
            <tr>
                <td>Ratio of disk spills to output records</td>
                <td>2.0</td>
            </tr>
            </tbody>
        </table>
    </a>
</div>
</p>
<h3>Suggestions</h3>
<p>
This heuristic is less straightforward than others, and it requires deeper hadoop knowledge. We are still working on finalizing the recommendation. Feedbacks welcomed! You could try:
<ol>
<li> Increase the size of in-memory sort buffer (mapreduce.task.io.sort.mb), default 100M</li>
<li> Increase the buffer spill percentage (mapreduce.map.sort.spill.percent, when it is reached a background thread will start spill buffer to disk), default value is 0.8.</li>
<li> Use combiner to lower the map output size. </li>
<li> Compress mapper output (set mapreduce.map.output.compress and mapreduce.map.output.compress.codec)</li>
</ol>
</p>