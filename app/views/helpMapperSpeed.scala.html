<p>
    This analysis shows the effectiveness of your mapper code.<br>
    This should allow you to determine if your mapper is CPU-bound or if your mapper is outputting huge amounts of data.
</p>
<p>
    This result of the analysis shows problems with mappers with significant slow speeds for the amount of data it needs to read.
</p>
<h5>Example</h5>
<p>
<div class="list-group">
    <a class="list-group-item list-group-item-danger" href="">
        <h4 class="list-group-item-heading">Mapper Speed</h4>
        <table class="list-group-item-text table table-condensed left-table">
            <thead><tr><th colspan="2">Severity: Critical</th></tr></thead>
            <tbody>
            <tr>
                <td>Number of tasks</td>
                <td>20</td>
            </tr>
            <tr>
                <td>Average task input size</td>
                <td>509 MB</td>
            </tr>
            <tr>
                <td>Average task speed</td>
                <td>56 KB/s</td>
            </tr>
            <tr>
                <td>Average task runtime</td>
                <td>2hr 5min 54sec</td>
            </tr>
            </tbody>
        </table>
    </a>
</div>
</p>
<h3>Suggestions</h3>
<p>
    If your mappers are CPU bound (Average task speed ~KB/s), then your mappers are performing significant CPU work,
    and you should consider optimizing your mapper code or check for inefficiencies in code. Alternatively, in rare
    cases, it may help to reduce the maximum size of input that each mapper can process.<br>
    <br>
    The maximum map split size is controlled by the "mapred.max.split.size" parameter. By decreasing this value
    below dfs.block.size, you can reduce the maximum input size for each mapper, thereby increase the number of mappers
    in your job.<br>
</p>
